{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Data preparation and model selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.linear_model import Ridge, Lasso, LinearRegression, ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import NuSVR\n",
    "from numpy import random\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import NuSVR\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "#TODO Deep learning model with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = pd.read_csv(\"data/X1.csv\", index_col=0)\n",
    "Y1 = pd.read_csv(\"data/Y1.csv\", header=None, names=['Weight'])\n",
    "X2 = pd.read_csv(\"data/X2.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataEncoder(BaseEstimator):\n",
    "    def __init__(self): # no *args or **kargs\n",
    "        pass\n",
    "    def fit(self, X, y=None):\n",
    "        return self # nothing else to do\n",
    "    def transform(self, X, y=None):\n",
    "        columns = ['Gender', 'Age', 'Height', 'Family history with overweight', 'Consumption of high caloric food',\n",
    "           'Consumption frequency of vegetables', 'Number of main meals daily', 'Food Consumption between meals', 'Smoke',\n",
    "           'Water consumption daily', 'Calories consumption monitoring', 'Physical activity frequency', 'Time using technology devices',\n",
    "           'Alcohol consumption', 'Usual transportation used']\n",
    "        X.columns = columns\n",
    "        X['Consumption frequency of vegetables'] = X['Consumption frequency of vegetables'].replace(\n",
    "            {1: '1. Never', 2: '2. Sometimes', 3: '3. Always'})\n",
    "        X['Number of main meals daily'] = X['Number of main meals daily'].replace(\n",
    "            {1: '1', 2: '2', 3: '3', 4: '3+'})\n",
    "        X['Water consumption daily'] = X['Water consumption daily'].replace(\n",
    "            {1: '1. Less than 1L', 2: '2. Between 1L and 2L', 3: '3. More than 2L'})\n",
    "        X['Physical activity frequency'] = X['Physical activity frequency'].replace(\n",
    "            {0: '1. I do not have', 1: '2. 1 or 2 days', 2: '3. 2 or 4 days', 3: '4. 4 or 5 days'})\n",
    "        X['Time using technology devices'] = X['Time using technology devices'].replace(\n",
    "            {0: '1. 0–2 hours', 1: '2. 3–5 hours', 2: '3. More than 5 hours'})\n",
    "        \n",
    "        ordinal_cat = ['Consumption frequency of vegetables', 'Number of main meals daily', 'Food Consumption between meals',\n",
    "               'Water consumption daily', 'Physical activity frequency', 'Time using technology devices',\n",
    "               'Alcohol consumption']\n",
    "        for cat in ordinal_cat:\n",
    "            X[cat] = X[cat].map(lambda x: sorted(X[cat].unique()).index(x)+1)\n",
    "\n",
    "        # Handling binary categorical features\n",
    "        X[['Family history with overweight', 'Consumption of high caloric food', 'Smoke', 'Calories consumption monitoring']] = X[[\n",
    "            'Family history with overweight', 'Consumption of high caloric food', 'Smoke', 'Calories consumption monitoring']].replace(to_replace=['no', 'yes'], value=[0, 1])\n",
    "        X[['Gender']] = X[['Gender']].replace(\n",
    "            to_replace=['Female', 'Male'], value=[0, 1])\n",
    "\n",
    "        X['Age'] = X['Age'].map(lambda x: np.log(x))\n",
    "\n",
    "        X[ordinal_cat] = X[ordinal_cat].apply(lambda x : np.exp(x))\n",
    "\n",
    "        return pd.get_dummies(X),y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutlierImputer(BaseEstimator):\n",
    "    def __init__(self): # no *args or **kargs\n",
    "        pass\n",
    "    def fit(self, X, y=None):\n",
    "        return self # nothing else to do\n",
    "    def transform(self, X, y):\n",
    "        df = pd.concat([X,y], axis=1)\n",
    "        for col in ['Age', 'Height', 'Weight']:\n",
    "            upper_lim = df[col].quantile(.95)\n",
    "            lower_lim = df[col].quantile(.05)\n",
    "\n",
    "            df.loc[(df[col] > upper_lim), col] = np.nan\n",
    "            df.loc[(df[col] < lower_lim), col] = np.nan\n",
    "        \n",
    "        df.dropna(inplace=True)\n",
    "        return df.drop(\"Weight\",axis=1), df['Weight']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection (Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def score_weight_class(bmi_pred, bmi_true, low, high):\n",
    "#     tol = 1\n",
    "#     vpred = (bmi_pred >= low - tol) & (bmi_pred < high+tol)\n",
    "#     vtrue = (bmi_true >= low) & (bmi_true < high)\n",
    "#     if vtrue.sum() == 0:\n",
    "#         print(\"no true samples here\")\n",
    "#         return 0\n",
    "#     rmse = np.sqrt(((bmi_true[vtrue]-bmi_pred[vtrue])**2).mean())\n",
    "#     rmse = rmse/(high-low+tol)  # normalize rmse in interval\n",
    "#     acc = (vpred & vtrue).sum()/vtrue.sum()\n",
    "#     return rmse*(1-acc)\n",
    "\n",
    "\n",
    "# def score_regression(ytrue, ypred, height):\n",
    "#     bmi_pred = ypred/(height*height)\n",
    "#     bmi_true = ytrue/(height*height)\n",
    "#     scores = []\n",
    "#     for bmi_low, bmi_high in zip([0, 18.5, 25, 30], [18.5, 25, 30, 100]):\n",
    "#         scores.append(score_weight_class(bmi_pred, bmi_true,\n",
    "#                                          low=bmi_low, high=bmi_high))\n",
    "#     return np.mean(scores)\n",
    "\n",
    "# def _score(estimator, X, y):\n",
    "#     ypred = estimator.predict_proba(X)\n",
    "#     print(ypred)\n",
    "#     return score_regression(y, ypred, X[6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Ensemble methods https://scikit-learn.org/stable/modules/ensemble.html\n",
    "\n",
    "models = {\n",
    "    'Lasso': Lasso(),\n",
    "    'Ridge': Ridge(),\n",
    "    'KNeighborsRegressor': KNeighborsRegressor(),\n",
    "    'ElasticNet': ElasticNet(),\n",
    "    'NuSVR': NuSVR(),\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'Lasso__alpha': random.uniform(low=0.0001, high=100, size=400),\n",
    "\n",
    "    'Ridge__alpha': random.uniform(low=0.0001, high=100, size=400),\n",
    "\n",
    "    'KNeighborsRegressor__weights': ['uniform', 'distance'],\n",
    "    'KNeighborsRegressor__n_neighbors': random.randint(5, 1000, size=400),\n",
    "\n",
    "    'ElasticNet__alpha':  random.uniform(low=0.0001, high=100, size=400),\n",
    "    'ElasticNet__l1_ratio': random.uniform(low=0.0001, high=1, size=400),\n",
    "\n",
    "    'NuSVR__nu': random.uniform(low=0.0001, high=1, size=400),\n",
    "    'NuSVR__C': random.uniform(low=0.001, high=100, size=400),\n",
    "    'NuSVR__kernel': ['linear', 'rbf'],\n",
    "    \n",
    "}\n",
    "\n",
    "X,y = OutlierImputer().transform(X1.copy(),Y1.copy())\n",
    "X,y = DataEncoder().transform(X,y)\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running RandomizedSearchCV for Lasso.\n",
      "Fitting 3 folds for each of 400 candidates, totalling 1200 fits\n",
      "Running RandomizedSearchCV for Ridge.\n",
      "Fitting 3 folds for each of 400 candidates, totalling 1200 fits\n",
      "Running RandomizedSearchCV for KNeighborsRegressor.\n",
      "Fitting 3 folds for each of 400 candidates, totalling 1200 fits\n",
      "Running RandomizedSearchCV for ElasticNet.\n",
      "Fitting 3 folds for each of 400 candidates, totalling 1200 fits\n",
      "Running RandomizedSearchCV for NuSVR.\n",
      "Fitting 3 folds for each of 400 candidates, totalling 1200 fits\n",
      "Running RandomizedSearchCV for Lasso.\n",
      "Fitting 5 folds for each of 400 candidates, totalling 2000 fits\n",
      "Running RandomizedSearchCV for Ridge.\n",
      "Fitting 5 folds for each of 400 candidates, totalling 2000 fits\n",
      "Running RandomizedSearchCV for KNeighborsRegressor.\n",
      "Fitting 5 folds for each of 400 candidates, totalling 2000 fits\n",
      "Running RandomizedSearchCV for ElasticNet.\n",
      "Fitting 5 folds for each of 400 candidates, totalling 2000 fits\n",
      "Running RandomizedSearchCV for NuSVR.\n",
      "Fitting 5 folds for each of 400 candidates, totalling 2000 fits\n",
      "Running RandomizedSearchCV for Lasso.\n",
      "Fitting 10 folds for each of 400 candidates, totalling 4000 fits\n",
      "Running RandomizedSearchCV for Ridge.\n",
      "Fitting 10 folds for each of 400 candidates, totalling 4000 fits\n",
      "Running RandomizedSearchCV for KNeighborsRegressor.\n",
      "Fitting 10 folds for each of 400 candidates, totalling 4000 fits\n",
      "Running RandomizedSearchCV for ElasticNet.\n",
      "Fitting 10 folds for each of 400 candidates, totalling 4000 fits\n",
      "Running RandomizedSearchCV for NuSVR.\n",
      "Fitting 10 folds for each of 400 candidates, totalling 4000 fits\n"
     ]
    }
   ],
   "source": [
    "# random_state=42,k=k,pert=0.04\n",
    "mlflow.set_experiment(\"Obsesity Regression\")\n",
    "for cv in [3,5,10]:\n",
    "    for key in models.keys():\n",
    "        with mlflow.start_run():\n",
    "            print(\"Running RandomizedSearchCV for %s.\" % key)\n",
    "            model = models[key]\n",
    "            param = {k : v for k,v in params.items() if key in k }\n",
    "            pipeline = Pipeline(steps=[\n",
    "                ('Scaler', StandardScaler()),\n",
    "                (key,model)\n",
    "            ])\n",
    "            \n",
    "            gs = RandomizedSearchCV(pipeline, param, n_iter=400, cv=KFold(n_splits=cv), n_jobs=-2,\n",
    "                                    verbose=8, scoring='neg_mean_absolute_error', refit='neg_mean_absolute_error',\n",
    "                                    random_state=42\n",
    "                                    )\n",
    "            \n",
    "            gs.fit(train_x, train_y)\n",
    "            mlflow.log_param(\"__MODEL__\", key)\n",
    "            mlflow.log_metric(\"score_train_mae\", float(gs.best_score_))\n",
    "            mlflow.log_metric(\"CV\", cv)\n",
    "            preds = gs.predict(test_x)\n",
    "            mlflow.log_metric(\"score_test_mae\", mean_absolute_error(preds,test_y))\n",
    "            mlflow.log_metric(\"score_test_rmse\", mean_squared_error(preds,test_y,squared=False))\n",
    "            \n",
    "            for key in gs.best_params_:\n",
    "                mlflow.log_param(key.split('__')[1], gs.best_params_[key])\n",
    "            mlflow.sklearn.log_model(gs.best_estimator_, \"best_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "run_id                                            b9db28108ff04907bc77c7f217d73dd4\n",
       "experiment_id                                                                    1\n",
       "status                                                                    FINISHED\n",
       "artifact_uri                     file:///C:/Users/marci/Dropbox%20%28PCSAMU%20S...\n",
       "start_time                                        2021-11-12 10:51:52.839000+00:00\n",
       "end_time                                          2021-11-12 10:52:04.354000+00:00\n",
       "metrics.score_test_rmse                                                   9.454336\n",
       "metrics.CV                                                                     3.0\n",
       "metrics.score_test_mae                                                    7.013637\n",
       "metrics.score_train_mae                                                  -7.984738\n",
       "params.__MODEL__                                                             Ridge\n",
       "params.C                                                                      None\n",
       "params.kernel                                                                 None\n",
       "params.nu                                                                     None\n",
       "params.alpha                                                    28.167307751568504\n",
       "params.l1_ratio                                                               None\n",
       "params.weights                                                                None\n",
       "params.n_neighbors                                                            None\n",
       "tags.mlflow.source.type                                                      LOCAL\n",
       "tags.mlflow.source.name          C:\\Users\\marci\\anaconda3\\lib\\site-packages\\ipy...\n",
       "tags.mlflow.user                                                             marci\n",
       "tags.mlflow.log-model.history    [{\"run_id\": \"b9db28108ff04907bc77c7f217d73dd4\"...\n",
       "Name: 13, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Getting the best experients from Mlflow\n",
    "df_experients = mlflow.search_runs(filter_string=\"metrics.score_test_mae < 9\")\n",
    "\n",
    "#Getting the best run id\n",
    "best_experients_run_id = df_experients.loc[df_experients['metrics.score_test_mae'].idxmin()]\n",
    "best_experients_run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('Scaler', StandardScaler()),\n",
      "                ('Ridge', Ridge(alpha=28.167307751568504))])\n"
     ]
    }
   ],
   "source": [
    "#Getting the best experients from Mlflow\n",
    "df_experients = mlflow.search_runs(filter_string=\"metrics.score_test_mae < 9\")\n",
    "\n",
    "#Getting the best run id\n",
    "best_experients_run_id = df_experients.loc[df_experients['metrics.score_test_mae'].idxmin()]['run_id']\n",
    "best_experients_mae_score = df_experients.loc[df_experients['metrics.score_test_mae'].idxmin()]['metrics.score_test_mae']\n",
    "#Load model\n",
    "model = mlflow.sklearn.load_model(\"runs:/\" + best_experients_run_id + \"/best_model\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict Y2\n",
    "X,_ = DataEncoder().transform(X2.copy())\n",
    "y_pred = model.predict(X)\n",
    "series_y = pd.Series(y_pred)\n",
    "series_y = series_y.append(pd.Series(best_experients_mae_score))\n",
    "series_y.to_csv('data/Y2.csv',index=False,header=False,sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Model selection (Classification)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(height, weight):\n",
    "    bmi = weight/height**2\n",
    "    if 0 < bmi < 18.5:\n",
    "        return 1\n",
    "    if 18.5 < bmi < 25.0:\n",
    "        return 2\n",
    "    if 25.0 < bmi < 30.0:\n",
    "        return 3\n",
    "    if bmi >=30.0:\n",
    "        return 4\n",
    "\n",
    "df = pd.concat([X1,Y1], axis=1)\n",
    "labels = df.apply(lambda x : get_label(x['Height'],x['Weight']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_class = df.copy()\n",
    "\n",
    "\n",
    "def get_label(height, weight):\n",
    "    bmi = weight/height**2\n",
    "    if 0 < bmi < 18.5:\n",
    "        return 1\n",
    "    if 18.5 < bmi < 25.0:\n",
    "        return 2\n",
    "    if 25.0 < bmi < 30.0:\n",
    "        return 3\n",
    "    if bmi >=30.0:\n",
    "        return 4\n",
    "\n",
    "df_class['label'] = df_class.apply(lambda x : get_label(x['Height'],x['Weight']),axis=1)\n",
    "df_class.drop('Weight', inplace=True,axis=1)\n",
    "\n",
    "\n",
    "X = pd.get_dummies(df_class.drop('label', axis=1))\n",
    "y = df_class['label']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"Obsesity Classification\")\n",
    "\n",
    "# TODO Ensemble methods https://scikit-learn.org/stable/modules/ensemble.html\n",
    "models = {\n",
    "    'RandomForestClassifier' : RandomForestClassifier()\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'RandomForestClassifier': {\n",
    "        'n_estimators': random.randint(1, 1000, 50),\n",
    "        'max_depth': random.randint(1, 1000, 50),\n",
    "        'max_features': ['sqrt', 'log2', 'auto'],\n",
    "        'min_samples_split': random.randint(1, 1000, 50),\n",
    "        'min_samples_leaf': random.randint(1, 1000, 50),\n",
    "    }\n",
    "}\n",
    "\n",
    "# X = pd.DataFrame(pipeline.fit_transform(df_class)).drop(18, axis=1)\n",
    "# y = df_class['label']\n",
    "# y = y.astype(int)\n",
    "X\n",
    "cv = 5\n",
    "for key in models.keys():\n",
    "    with mlflow.start_run():\n",
    "        print(\"Running RandomizedSearchCV for %s.\" % key)\n",
    "        model = models[key]\n",
    "        param = params[key]\n",
    "        gs = RandomizedSearchCV(model, param, n_iter=50, cv=cv, n_jobs=-2,\n",
    "                                verbose=3, scoring='accuracy'\n",
    "                                )\n",
    "        gs.fit(X_resampled, y_resampled)\n",
    "        mlflow.log_param(\"Classifier\", key)\n",
    "        mlflow.log_metric(\"best_score\", float(gs.best_score_))\n",
    "        mlflow.log_metric(\"CV\", cv)\n",
    "        for key in gs.best_params_:\n",
    "            mlflow.log_param(key, gs.best_params_[key])\n",
    "        mlflow.sklearn.log_model(gs.best_estimator_, \"best_model\")\n",
    "# def eval(predict, target):\n",
    "\n",
    "#     rmse = np.sqrt(mean_squared_error(predict, target))\n",
    "#     mae = mean_absolute_error(predict, target)\n",
    "#     r2 = r2_score(predict, target)\n",
    "#     return rmse, mae, r2\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=42, test_size=0.1)\n",
    "\n",
    "lg = KNeighborsClassifier()\n",
    "lg.fit(X_train, y_train)\n",
    "preds = lg.predict(X_test)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, preds, labels=[1,2,3,4])\n",
    "\n",
    "sns.heatmap(conf_matrix,annot=True,fmt='g',xticklabels=['underweight','normal','overweight','obese'],yticklabels=['underweight','normal','overweight','obese'])\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "643983cb912722448ab70204d5f58fc7d67fc5fc0e3de367d07cf898678346f4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
