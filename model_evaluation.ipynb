{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Data preparation and model selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.linear_model import Ridge, Lasso, LinearRegression, ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.svm import NuSVR\n",
    "from numpy import random\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import NuSVR\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "#TODO Deep learning model with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = pd.read_csv(\"data/X1.csv\", index_col=0)\n",
    "Y1 = pd.read_csv(\"data/Y1.csv\", header=None, names=['Weight'])\n",
    "X2 = pd.read_csv(\"data/X2.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataEncoder(BaseEstimator):\n",
    "    def __init__(self): # no *args or **kargs\n",
    "        pass\n",
    "    def fit(self, X, y=None):\n",
    "        return self # nothing else to do\n",
    "    def transform(self, X, y=None):\n",
    "        columns = ['Gender', 'Age', 'Height', 'Family history with overweight', 'Consumption of high caloric food',\n",
    "           'Consumption frequency of vegetables', 'Number of main meals daily', 'Food Consumption between meals', 'Smoke',\n",
    "           'Water consumption daily', 'Calories consumption monitoring', 'Physical activity frequency', 'Time using technology devices',\n",
    "           'Alcohol consumption', 'Usual transportation used']\n",
    "        X.columns = columns\n",
    "        X['Consumption frequency of vegetables'] = X['Consumption frequency of vegetables'].replace(\n",
    "            {1: '1. Never', 2: '2. Sometimes', 3: '3. Always'})\n",
    "        X['Number of main meals daily'] = X['Number of main meals daily'].replace(\n",
    "            {1: '1', 2: '2', 3: '3', 4: '3+'})\n",
    "        X['Water consumption daily'] = X['Water consumption daily'].replace(\n",
    "            {1: '1. Less than 1L', 2: '2. Between 1L and 2L', 3: '3. More than 2L'})\n",
    "        X['Physical activity frequency'] = X['Physical activity frequency'].replace(\n",
    "            {0: '1. I do not have', 1: '2. 1 or 2 days', 2: '3. 2 or 4 days', 3: '4. 4 or 5 days'})\n",
    "        X['Time using technology devices'] = X['Time using technology devices'].replace(\n",
    "            {0: '1. 0–2 hours', 1: '2. 3–5 hours', 2: '3. More than 5 hours'})\n",
    "        X['Food Consumption between meals'] = X['Food Consumption between meals'].replace(\n",
    "            {'no' : '1. No', 'Sometimes' : '2. Sometimes', 'Frequently': '3. Frequently','Always': '4. Always'})\n",
    "\n",
    "        #X['Height'] = X['Height']*100\n",
    "\n",
    "        X[\"Usual transportation used\"] = X[\"Usual transportation used\"].apply(lambda x : \"Public_Transportation\" if x == \"Public_Transportation\" else \"Other\")\n",
    "        X[\"Public Transportation\"] = X.apply(lambda x : \"yes\" if x['Usual transportation used'] == \"Public_Transportation\" else \"no\", axis=1)\n",
    "        X.drop(\"Usual transportation used\", inplace=True, axis=1)\n",
    "\n",
    "        ordinal_cat = ['Consumption frequency of vegetables', 'Number of main meals daily', 'Food Consumption between meals',\n",
    "               'Water consumption daily', 'Physical activity frequency', 'Time using technology devices',\n",
    "               'Alcohol consumption']\n",
    "        for cat in ordinal_cat:\n",
    "            X[cat] = X[cat].map(lambda x: sorted(X[cat].unique()).index(x)+1)\n",
    "\n",
    "        # Handling binary categorical features\n",
    "        X[['Family history with overweight', 'Consumption of high caloric food', 'Smoke', 'Calories consumption monitoring','Public Transportation']] = X[[\n",
    "            'Family history with overweight', 'Consumption of high caloric food', 'Smoke', 'Calories consumption monitoring','Public Transportation']].replace(to_replace=['no', 'yes'], value=[0, 1])\n",
    "        X[['Gender']] = X[['Gender']].replace(\n",
    "            to_replace=['Female', 'Male'], value=[0, 1])\n",
    "\n",
    "        X.drop([\"Smoke\",\"Calories consumption monitoring\"], inplace=True, axis=1)\n",
    "\n",
    "        X['Age'] = X['Age'].map(lambda x: np.log(x))\n",
    "\n",
    "        #X[ordinal_cat] = X[ordinal_cat].apply(lambda x : np.exp(x))\n",
    "\n",
    "        return X.astype(np.float64),y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class OutlierImputer(BaseEstimator):\n",
    "#     def __init__(self): # no *args or **kargs\n",
    "#         pass\n",
    "#     def fit(self, X, y=None):\n",
    "#         return self # nothing else to do\n",
    "#     def transform(self, X, y):\n",
    "#         df = pd.concat([X,y], axis=1)\n",
    "#         for col in ['Age', 'Height', 'Weight']:\n",
    "#             upper_lim = df[col].quantile(.95)\n",
    "#             lower_lim = df[col].quantile(.05)\n",
    "\n",
    "#             df.loc[(df[col] > upper_lim), col] = np.nan\n",
    "#             df.loc[(df[col] < lower_lim), col] = np.nan\n",
    "        \n",
    "#         df.dropna(inplace=True)\n",
    "#         return df.drop(\"Weight\",axis=1), df['Weight']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection (Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def score_weight_class(bmi_pred, bmi_true, low, high):\n",
    "    tol = 1\n",
    "    vpred = (bmi_pred >= low - tol) & (bmi_pred < high+tol)\n",
    "    vtrue = (bmi_true >= low) & (bmi_true < high)\n",
    "    if vtrue.sum() == 0:\n",
    "        print(\"no true samples here\")\n",
    "        return 0\n",
    "    rmse = np.sqrt(((bmi_true[vtrue]-bmi_pred[vtrue])**2).mean())\n",
    "    rmse = rmse/(high-low+tol)  # normalize rmse in interval\n",
    "    acc = (vpred & vtrue).sum()/vtrue.sum()\n",
    "    return rmse*(1-acc)\n",
    "\n",
    "\n",
    "def score_regression(ytrue, ypred, height):\n",
    "    bmi_pred = ypred/(height*height)\n",
    "    bmi_true = ytrue/(height*height)\n",
    "    scores = []\n",
    "    for bmi_low, bmi_high in zip([0, 18.5, 25, 30], [18.5, 25, 30, 100]):\n",
    "        scores.append(score_weight_class(bmi_pred, bmi_true,\n",
    "                                         low=bmi_low, high=bmi_high))\n",
    "    return np.mean(scores)\n",
    "\n",
    "# def _score(estimator, X, y):\n",
    "#     ypred = estimator.predict(X)\n",
    "#     return score_regression(np.array(y), np.array(ypred), np.array(X[2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Ensemble methods https://scikit-learn.org/stable/modules/ensemble.html\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "X,y = DataEncoder().transform(X1.copy(),Y1.copy())\n",
    "n_columns = len(X.columns)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "models = {\n",
    "    # 'Lasso': Lasso(),\n",
    "    # 'Ridge': Ridge(),\n",
    "    # 'KNeighborsRegressor': KNeighborsRegressor(),\n",
    "    # 'SVR' : SVR(),\n",
    "    'MLPRegressor' : MLPRegressor()\n",
    "}\n",
    "\n",
    "params = {\n",
    "    # 'Lasso__alpha': random.uniform(low=0.0001, high=50, size=400),\n",
    "\n",
    "    # 'Ridge__alpha': random.uniform(low=0.0001, high=50, size=400),\n",
    "    # 'Ridge__solver' : ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga', 'lbfgs'],\n",
    "\n",
    "    # 'KNeighborsRegressor__weights': ['uniform', 'distance'],\n",
    "    # 'KNeighborsRegressor__n_neighbors': random.randint(5, 200, size=400),\n",
    "    # 'KNeighborsRegressor__algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "    # 'KNeighborsRegressor__leaf_size': random.randint(20, 200, size=400),\n",
    "\n",
    "    # 'SVR__kernel': [\"rbf\", \"sigmoid\", \"linear\", \"poly\"],\n",
    "    # 'SVR__C': random.uniform(low=0.001, high=200, size=400),\n",
    "    # 'SVR__epsilon': random.uniform(low=0.001, high=200, size=400),\n",
    "    \n",
    "    \"MLPRegressor__hidden_layer_sizes\": list(zip(random.randint(10, 30, size=200),random.randint(1, 200, size=200))), \n",
    "    \"MLPRegressor__solver\": [\"lbfgs\", \"sgd\", \"adam\"],\n",
    "    \"MLPRegressor__learning_rate\": ['constant', 'invscaling', 'adaptive'], \n",
    "    \"MLPRegressor__alpha\": random.uniform(low=0.0001, high=200, size=200),\n",
    "    \"MLPRegressor__activation\": ['logistic', 'tanh', 'relu', 'identity'],\n",
    "    'MLPRegressor__max_iter': random.randint(200, 1000, size=200),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running RandomizedSearchCV for MLPRegressor.\n",
      "Fitting 5 folds for each of 400 candidates, totalling 2000 fits\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Obsesity Regression\")\n",
    "\n",
    "for key in models.keys():\n",
    "    with mlflow.start_run():\n",
    "        print(f\"Running RandomizedSearchCV for {key}.\")\n",
    "        model = models[key]\n",
    "        param = {k : v for k,v in params.items() if key in k or 'KernelPCA' in k}\n",
    "        pipeline = Pipeline(steps=[\n",
    "            ('Scaler', StandardScaler()),\n",
    "            (key,model)\n",
    "        ])\n",
    "        \n",
    "        rs = RandomizedSearchCV(pipeline, param, n_iter=400, cv=KFold(n_splits=5), n_jobs=-2,\n",
    "                                verbose=8, scoring=['neg_mean_absolute_error','neg_root_mean_squared_error'], refit='neg_mean_absolute_error',\n",
    "                                random_state=42\n",
    "                                )\n",
    "        \n",
    "        rs.fit(X_train, y_train)\n",
    "        mlflow.log_param(\"Best Estimator\", key)\n",
    "        mlflow.log_metric(\"score_train_mae\", float(rs.best_score_))\n",
    "        preds = rs.predict(X_test)\n",
    "        mlflow.log_metric(\"score_test_mae\", mean_absolute_error(preds,y_test))\n",
    "        mlflow.log_metric(\"score_test_rmse\", mean_squared_error(preds,y_test,squared=False))\n",
    "        mlflow.log_metric(\"score_test_reg\", score_regression(y_test['Weight'].ravel(),preds.ravel(),X_test['Height'].ravel()))\n",
    "        \n",
    "        for key in rs.best_params_:\n",
    "            mlflow.log_param(key.split('__')[1], rs.best_params_[key])\n",
    "        mlflow.sklearn.log_model(rs.best_estimator_, \"best_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('Scaler', StandardScaler()),\n",
      "                ('MLPRegressor',\n",
      "                 MLPRegressor(activation='logistic', alpha=23.707441290955774,\n",
      "                              hidden_layer_sizes=(114, 196),\n",
      "                              learning_rate='adaptive', max_iter=454,\n",
      "                              solver='sgd'))])\n"
     ]
    }
   ],
   "source": [
    "#Getting the best experients from Mlflow\n",
    "df_experients = mlflow.search_runs(filter_string=\"metrics.score_test_reg < 0.12\")\n",
    "\n",
    "#Getting the best run id\n",
    "best_experients_run_id = df_experients.loc[df_experients['metrics.score_test_reg'].idxmin()]['run_id']\n",
    "best_experients_reg_score = df_experients.loc[df_experients['metrics.score_test_reg'].idxmin()]['metrics.score_test_reg']\n",
    "#Load model\n",
    "model = mlflow.sklearn.load_model(\"runs:/\" + best_experients_run_id + \"/best_model\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predict Y2\n",
    "X,_ = DataEncoder().transform(X2.copy())\n",
    "y_pred = model.predict(X)\n",
    "series_y = pd.Series(y_pred)\n",
    "series_y = series_y.append(pd.Series(best_experients_reg_score))\n",
    "series_y.to_csv('data/Y2.csv',index=False,header=False,sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Model selection (Classification)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(height, weight):\n",
    "    bmi = weight/height**2\n",
    "    if 0 < bmi < 18.5:\n",
    "        return 1\n",
    "    if 18.5 < bmi < 25.0:\n",
    "        return 2\n",
    "    if 25.0 < bmi < 30.0:\n",
    "        return 3\n",
    "    if bmi >=30.0:\n",
    "        return 4\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "df_true = pd.concat([X_test,y_test], axis=1)\n",
    "df_pred = pd.concat([X_test,pd.DataFrame(y_pred, columns=['Weight'])], axis=1)\n",
    "true_labels = df_true.apply(lambda x : get_label(x['Height'],x['Weight']),axis=1).ravel()\n",
    "pred_labels = df_true.apply(lambda x : get_label(x['Height'],x['Weight']),axis=1).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  0,  0,  0],\n",
       "       [ 0, 32,  0,  0],\n",
       "       [ 0,  0, 12,  0],\n",
       "       [ 0,  0,  0,  3]], dtype=int64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(true_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_class = df.copy()\n",
    "\n",
    "\n",
    "def get_label(height, weight):\n",
    "    bmi = weight/height**2\n",
    "    if 0 < bmi < 18.5:\n",
    "        return 1\n",
    "    if 18.5 < bmi < 25.0:\n",
    "        return 2\n",
    "    if 25.0 < bmi < 30.0:\n",
    "        return 3\n",
    "    if bmi >=30.0:\n",
    "        return 4\n",
    "\n",
    "df_class['label'] = df_class.apply(lambda x : get_label(x['Height'],x['Weight']),axis=1)\n",
    "df_class.drop('Weight', inplace=True,axis=1)\n",
    "\n",
    "\n",
    "X = pd.get_dummies(df_class.drop('label', axis=1))\n",
    "y = df_class['label']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"Obsesity Classification\")\n",
    "\n",
    "# TODO Ensemble methods https://scikit-learn.org/stable/modules/ensemble.html\n",
    "models = {\n",
    "    'RandomForestClassifier' : RandomForestClassifier()\n",
    "}\n",
    "\n",
    "params = {\n",
    "    'RandomForestClassifier': {\n",
    "        'n_estimators': random.randint(1, 1000, 50),\n",
    "        'max_depth': random.randint(1, 1000, 50),\n",
    "        'max_features': ['sqrt', 'log2', 'auto'],\n",
    "        'min_samples_split': random.randint(1, 1000, 50),\n",
    "        'min_samples_leaf': random.randint(1, 1000, 50),\n",
    "    }\n",
    "}\n",
    "\n",
    "# X = pd.DataFrame(pipeline.fit_transform(df_class)).drop(18, axis=1)\n",
    "# y = df_class['label']\n",
    "# y = y.astype(int)\n",
    "X\n",
    "cv = 5\n",
    "for key in models.keys():\n",
    "    with mlflow.start_run():\n",
    "        print(\"Running RandomizedSearchCV for %s.\" % key)\n",
    "        model = models[key]\n",
    "        param = params[key]\n",
    "        gs = RandomizedSearchCV(model, param, n_iter=50, cv=cv, n_jobs=-2,\n",
    "                                verbose=3, scoring='accuracy'\n",
    "                                )\n",
    "        gs.fit(X_resampled, y_resampled)\n",
    "        mlflow.log_param(\"Classifier\", key)\n",
    "        mlflow.log_metric(\"best_score\", float(gs.best_score_))\n",
    "        mlflow.log_metric(\"CV\", cv)\n",
    "        for key in gs.best_params_:\n",
    "            mlflow.log_param(key, gs.best_params_[key])\n",
    "        mlflow.sklearn.log_model(gs.best_estimator_, \"best_model\")\n",
    "# def eval(predict, target):\n",
    "\n",
    "#     rmse = np.sqrt(mean_squared_error(predict, target))\n",
    "#     mae = mean_absolute_error(predict, target)\n",
    "#     r2 = r2_score(predict, target)\n",
    "#     return rmse, mae, r2\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=42, test_size=0.1)\n",
    "\n",
    "lg = KNeighborsClassifier()\n",
    "lg.fit(X_train, y_train)\n",
    "preds = lg.predict(X_test)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, preds, labels=[1,2,3,4])\n",
    "\n",
    "sns.heatmap(conf_matrix,annot=True,fmt='g',xticklabels=['underweight','normal','overweight','obese'],yticklabels=['underweight','normal','overweight','obese'])\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "643983cb912722448ab70204d5f58fc7d67fc5fc0e3de367d07cf898678346f4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
